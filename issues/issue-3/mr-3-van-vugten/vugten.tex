 \documentclass[empirical, authordate, meta]{jote-new-article}
% \usepackage[style=apa]{biblatex}
% \addbibresource{bibliography.bib}\usepackage{graphicx}\usepackage{hyperref}



\begin{filecontents}{bibliography.bib}

  @article{OpenSourceCollaboration2015,
    title       = {Estimating the reproducibility of psychological science},
    author      = {Collaboration, Open Science},
    number      = {6251},
    volume      = {349},
    year        = {2015},
    journal     = {Science}
}


@article{Mazzola2013,
    title       = {Forgetting what we learned as graduate students: HARKing and selective outcome reporting in I--O},
    author      = {Mazzola, J.J. and Deuling, J.K.},
    number      = {3},
    volume      = {6},
    year        = {2013},
    pages       = {279--284},
    journal     = {journal articles. Industrial and Organizational}
}


@article{Hugten2021,
    title       = {The State of the Art of Hypothesis Testing in the Social Sciences},
    author      = {Hugten, J. and Witteloostuijn, A.},
    publisher   = {VU University Press},
    year        = {2021},
    pages       = {167--185},
    journal     = {A Future for Economics}
}


@article{Bedeian2010,
    title       = {Management science on the credibility bubble},
    author      = {Bedeian, A.G. and Taylor, S.G. and Miller, A.N.},
    number      = {4},
    volume      = {9},
    year        = {2010},
    pages       = {715--725},
    journal     = {Cardinal sins and various misdemeanors. Academy of Management Learning \&}
}


@article{Rubin2017,
    title       = {When does HARKing hurt? Identifying when different types of undisclosed post hoc hypothesizing harm scientific progress. Review of General Psychology, 21(4},
    author      = {Rubin, M.},
    year        = {2017},
    pages       = {308--320}
}


@article{Witteloostuijn2016,
    title       = {What happened to Popperian falsification? Publishing neutral and negative findings. Cross Cultural \&},
    author      = {Witteloostuijn, A.},
    number      = {3},
    volume      = {23},
    year        = {2016},
    pages       = {481--508},
    journal     = {Strategic}
}


@article{Johns2019,
    title       = {GUIDEPOST: Departures from conventional wisdom: Where's the next opposite effect? Academy of Management Discoveries},
    author      = {Johns, G.},
    doi         = {10.5465/amd.2019.0226.},
    year        = {2019}
}


@article{Davis1971,
    title       = {That's interesting! Towards a phenomenology of sociology and a sociology of phenomenology. Philosophy of the Social Sciences, 1(2},
    author      = {Davis, M.S.},
    year        = {1971},
    pages       = {309--344}
}


@book{Schwab2012,
    title       = {Using baseline models to improve theories about emerging markets In Wang, C.L., Ketchen, D.J. and Bergh, D.D. (Ed.) West Meets East: Toward Methodological Exchange (Research Methodology in Strategy and Management},
    author      = {Schwab, A. and undefined, Starbuck},
    volume      = {7},
    publisher   = {Emerald Group Publishing Limited},
    place       = {Bingley},
    year        = {2012},
    pages       = {3--33}
}


@article{Hines1988,
    title       = {Popper's methodology of falsificationism and accounting research},
    author      = {Hines, R.D.},
    number      = {4},
    volume      = {63},
    year        = {1988},
    pages       = {657--662},
    journal     = {The Accounting Review}
}


@article{Lakatos1970,
    title       = {Falsification and the methodology of scientific research programmes},
    author      = {Lakatos, I.},
    publisher   = {Cambridge University Press},
    year        = {1970},
    pages       = {91--196},
    journal     = {Criticism and the Growth of Knowledge}
}


@article{Søberg2005,
    title       = {The Duhem-Quine thesis and experimental economics: A reinterpretation. Journal of Economic Methodology, 12(4},
    author      = {Søberg, M.},
    year        = {2005},
    pages       = {581--597}
}


@article{Weick1999,
    title       = {Conclusion: Theory Construction as Disciplined Reflexivity: Tradeoffs in the 90s},
    author      = {Weick, K.E.},
    number      = {4},
    volume      = {24},
    year        = {1999},
    pages       = {797--806},
    journal     = {The Academy of Management Review}
}


@article{Cross1982,
    title       = {The Duhem-Quine thesis, Lakatos and the appraisal of theories in macroeconomics},
    author      = {Cross, R.},
    number      = {366},
    volume      = {92},
    year        = {1982},
    pages       = {320--340},
    journal     = {The Economic Journal}
}


@article{Spector2011,
    title       = {Methodological urban legends: The misuse of statistical control variables. Organizational},
    author      = {Spector, P.E. and Brannick, M.T.},
    number      = {2},
    volume      = {14},
    year        = {2011},
    pages       = {287--305},
    journal     = {Research}
}


@article{Haveman1993,
    title       = {Follow the leader: Mimetic isomorphism and entry into new markets. Administrative},
    author      = {Haveman, H.A.},
    number      = {4},
    volume      = {38},
    year        = {1993},
    pages       = {593--627},
    journal     = {Science Quarterly}
}


@article{Bettis2012,
    title       = {The search for asterisks: Compromised statistical tests and flawed theories. Strategic},
    author      = {Bettis, R.A.},
    number      = {1},
    volume      = {33},
    year        = {2012},
    pages       = {108--113},
    journal     = {Management}
}


@article{Wasserstein2019,
    title       = {Moving to a World Beyond “p < 0.05},
    author      = {Wasserstein, R.L. and Schirm, A.L. and Lazar, N.A.},
    number      = {sup1},
    volume      = {73},
    year        = {2019},
    pages       = {1--19},
    journal     = {The American Statistician}
}


@article{Schwab2011,
    title       = {Perspective—researchers should make thoughtful assessments instead of null-hypothesis significance tests. Organization Science, 22(4},
    author      = {Schwab, A. and Abrahamson, E. and Starbuck, W.H. and Fidler, F.},
    year        = {2011},
    pages       = {1105--1120}
}

\end{filecontents}
% \addbibresource{./bibliography.bib}
\addbibresource{bibliography.bib}
\jotetitle{An Introduction to Complementary Explanation}
\keywordsabstract{Philosophy of science, Falsification, Publication bias, Complementary explanation}
\runningauthor{van Hugten}
\jname{Journal of Trial and Error}
\jyear{2022}
\paperdoi{10.36850/mr3}
\paperreceived{August 29. 2021}
\author[1]{Joeri van Hugten{\orcid{https://orcid.org/0000-0002-8040-5192}}}
\authorone{Joeri van Hugten}
\affil[1]{Vrije Universiteit Amsterdam}
\corremail{\href{mailto:j.g.w.j.van.hugten@vu.nl}{j.g.w.j.van.hugten@vu.nl}}
\corraddress{Vrije Universiteit Amsterdam}
\paperaccepted{May 12, 2022}
\paperpublished{3 March, 2022}
% \paperissued{3 March, 2022}
\paperpublisheddate{2022-03-02}
\jwebsite{https://jtrialerror.com}

\acknowledgments{I would to thank the reviewers, Pablo Martin de Holan, Jana Retkowsky, Arjen van Witteloostuijn, and the OT reading group at Tilburg University for their encouragement and valuable feedback on an earlier version of this work.}
\begin{document}
\begin{frontmatter}
\maketitle
\begin{abstract}
This paper introduces the practice of complementary explanation; the practice of taking a published result and writing a focused paper that rigorously and systematically describes the implications for a theory that would be rejected by those results. Such spotlighting of a rejected theory counteracts the common alignment between theory and result in published work.
\end{abstract}
\end{frontmatter}


\lettrine{T}{he reliability of} the social sciences is threatened by underreporting. Underreporting refers to reported evidence not reflecting all collected evidence. This is concerning if reported evidence is a systematically disproportionate subset of collected evidence. Currently, this is the case with reported evidence being severely biased toward evidence that supports theories. For example, a large-scale replication of 100 psychology experiments replicated only 36 out of 97 significant results \parencite{Collaboration2015}(which should be more representative of all collected evidence) are only 33\% supported and 42\% rejected \parencite{Mazzola2013, Hugten2021}

Underreporting is caused by underreporting practices such as hypothesizing after the results are known (HARKing) and not writing up all conducted tests. This leads to bias because especially results that do not support a paper's theory tend to be the ones not written up, and hypotheses made after the results are known tend to be ones that are in line with those results. Underreporting practices are prevalent. Measuring socially undesirable behavior is difficult, but best efforts suggest that 91\% of academics know faculty who engaged in HARKing in the past year, 77\% knows faculty who selected data that would support their hypothesis and withheld the rest \parencite{Bedeian2010, Rubin2017}

This paper proposes a practice to challenge theories and counteract underreporting. That practice is based on the falsificationist hypothetico-deductive philosophy \parencite{Witteloostuijn2016}



\subsection{Underreporting practices as a neglect of falsification}

Besides psychological factors (e.g., confirmation bias) and sociological factors (e.g., not undermining your colleague's theories), beliefs about what is important also underlie underreporting practices. In this section, I speculate about underlying beliefs for three aspects of underreporting practices, as well as a falsificationist principle that speaks to that belief. The posited beliefs are overlapping, and it turns out that falsificationist principles form a coherent opposition to those beliefs.






In the theory and hypothesis sections, why do HARKed hypotheses tend to be in line with the result? My personal intuition is that researchers understand that, at the level of the research program, theories aim to explain phenomena, but that this gets mistakenly transferred to believing that also hypotheses aim to explain results, at the level of the individual study. Given that aim, it follows that hypotheses that are not in line with the result are not useful \parencite{Johns2019}(as long as they are tightly connected to a theory).

In the results section, why are results against hypothesis the underreported kinds of result? A possible underlying belief is that results that support hypotheses grant more valuable knowledge. In direct contrast, a key principle of falsification is that results against hypotheses give more valuable knowledge. For instance, seminal falsificationist Karl Popper argues that we learn more from results against hypotheses. Broadly speaking, the argument is that a result that supports a hypothesis does not imply that the theory is true, because that is affirming the consequent. Specifically, such an inference would go: ‘if theory T is true, then data D should be observed' (i.e., the hypothesis), ‘data D is observed' (i.e., the result is in line with the hypothesis), ‘Therefore, theory T is true'. This is a logical fallacy because there may be alternative explanations for data D. Therefore, researchers try hard to rule out such alternative explanations by using random assignment, control variables, or more advanced statistical techniques. By contrast, a rejected hypothesis does imply that at least one premise in the theory or operationalization is false, because it is denying the consequent which is a valid form of argument (even if alternative explanations were not excluded). Less extremely, \parencite{Davis1971}

In the discussion section, if a rejected hypothesis is reported, why is the expectation that authors explain the result? I speculate that the underlying belief may be that explaining data is a more important goal than improving theory. By contrast, falsificationist principles hold improving theory as the main goal. Therefore, those principles suggest that discussion sections build on the result to contribute contingencies that make the theory less simple or generalizable, and as a result, more accurate \parencite[eg,]{Lakatos1970, Cross1982}. Contributing contingencies can also happen in the process of explaining a result. However, the distinction is especially clear when discussion sections bring in a completely different theory that does fit the result. The distinction also becomes clearer if one imagines a more extreme alternate world in which discussion sections purposefully attempt to bring in additional theories that are opposite to the result. By contrast, current practice is that no further discussion is needed once the result is explained.

Overall, the argument is not that following the principles of falsification leads to more ethical research; it probably only affects the type of results that are underreported, not the extent of underreporting. That is, if researchers believed that rejected hypotheses lead to more valuable knowledge, then underreporting might start tending toward underreporting results that support hypotheses. Currently, the tendency is to underreport rejected hypotheses, so a practice based on principles of falsification can help bring balance.


\begin{table}[t!] 
\begin{fullwidth}

\caption{Possible beliefs underlying underreporting practices.}
\label{tab:1}
  
\begin{tabularx}{\columnwidth}{@{}>{\raggedright\arraybackslash}p{0.3\linewidth} >{\raggedright\arraybackslash}p{0.35\linewidth} >{\raggedright\arraybackslash}p{0.25\linewidth}@{}}

  \emph{Underreporting practice} & 
  \emph{Possible underlying belief} & \emph{Related falsificationist principle}\\
HARKed hypothesis tend to be in line with the result & Theories aim to explain the world, therefore hypotheses aim to explain the result & Hypotheses aim to challenge theory\\
Unreported results tend to be against the theory  & Supported hypotheses give more valuable knowledge & Rejected hypotheses give more valuable knowledge\\
Discussion section focus on explaining the result & Explaining the result is the goal of a paper & Challenging the theory is the goal of a paper\\


\end{tabularx}
\end{fullwidth}


\end{table}


\subsection{A proposed counteracting practice: complementary explanation}

Because of the opposition to falsificationist principles in the aspects of underreporting practices, I propose that a practice that thoroughly applies those falsificationist principles can counteract underreporting practices. Specifically, I propose complementary explanation (CE). 

The term ‘complementary explanation' is a variation on the term ‘alternative explanation'. An alternative explanation is an explanation for a result and an alternative to the hypothesis development (assuming that the result was in line with that hypothesis). Alternative explanations are the main threat that Popper aimed to avoid. By contrast, a complementary explanation (CE -- countable) is an explanation for the opposite of a result, so it is a logical complement to the hypothesis development (assuming that the result was in line with that hypothesis). For example, if a quantitative study finds a positive coefficient, a CE for that result is a set of arguments that imply a negative coefficient. Similarly, for a qualitative study's causal story between high X and high Y, a theory's implication of a negative relation is a CE. If a study's result is inconsistent with its hypothesis, then the original hypothesis development is a CE. Even if a study does not have a hypothesis for a particular relation, an explanation of the opposite of its result is a CE. One result can have multiple CEs.

To appreciate CE's unique focus, table 2 positions CE in the context of a comprehensive list of similar existing practices. CE is similar to counterarguments, competing hypotheses, meaningful baselines, or theory-driven null hypotheses \parencite[][e,.,g,.]{Schwab2012}





\begin{table}

    \caption{Complementary explanation in relation to existing practices.
    }
    \label{tab:2}
  
\begin{tabular}{c  c  c}

  Focus on before the result is known & Focus on after the result is known\\
Focus on the result & Dominant practice & Abduction, CHarking, Harking, RHarking, Tharking\\
Focus on the rejected hypothesis  & Counterargument, competing hypothesis, meaningful baseline, theory-driven null-hypothesis & Complementary explanation, SHarking\\

\end{tabular}


\end{table}


CE is like HARKing and spinoffs like Tharking (i.e., transparently hypothesizing after the results are known \parencite{Hollenbeck2017, Rubin2017} and abduction \parencite{Locke2008, Schwab2017} in that all those practices happen after a result is found. However, the difference is that those practices aim to explain a result (although RHarking is, in principal, also open to rejected hypotheses \parencite{Rubin2017}). For example, abduction would never involve explaining the opposite of the result. In other words, hypotheses made after the results are known tend to be ones that are in line with those results. But they need not be that way. CE is like transparently making a hypothesis after the result is known, that is opposite to that result. That shift in focus counteracts the threat of HARKing to research reliability. Finally, CE is like SHarking (suppressing hypotheses after the results are known); the most threatening form of HARKing \parencite{Rubin2017}, except that SHarking focuses on suppressing rejected hypotheses while CE adds exactly such hypotheses.



\subsection{CE Steps}

The steps to interpret supportive results seem clear: e.g., 1) p<0.05, 2) hypothesis supported, and 3) more confidence in the theory (but see \textcite{Wasserstein2019} for how it is not that simple). By contrast, the application of falsification is impeded by a lack of such clear steps. CE is a way to codify falsificationist interpretation steps. Table 3 summarizes these steps. 





\begin{table}
\caption{\emph{CE Steps.}}
\label{tab:3}
  
\begin{fullwidth}
\begin{tabularx}{\columnwidth}{l  l}

  Steps & Notes\\
0. Find a result & While reading, one might stumble upon a published finding that is striking if interpreted from the perspective of a different theory. The finding might even be merely a control variable for the original paper. 
\newline Results with strong measures and research designs are ideal so that the result being opposite to a CE is clearly attributable to the theory. \\
1. Develop a CE for that result & What collection of premises suggest the opposite of the result? Premises that are  straightforward and commonly held  associations of concepts are ideal. That collection becomes the CE. If the result is opposite to the original hypothesis, then the original hypothesis development is a CE.\\
2. Identify a premise in that CE to challenge & By design, the CE is not in line with the result. So, at least one of its premises must be too simple. \\
3. Suggest a complication for that challenged premise & What would be one way in which we could complicate the challenged premise?\\
4. Evaluate that complication's effect on accuracy. & Does the complication increase accuracy? Is the complication plausible?\\
5. Iterate over steps 3-4. When out of ideas, compare complications. & The most  simple and generalizable  complication that can  accurately  predict the result is the ideal.\\
6. Iterate over steps 2-3-4-5. When out of ideas, compare challenges. & The  less paper-specific the challenged premise, the greater the theoretical contribution.\\
7. Specify the contribution & Concisely and concretely describe the new insight.  \newline E.g., ‘Premise 1 should be replaced by premise 1*' or ‘Premise 1 is moderated by M'.\\


\end{tabularx}
\end{fullwidth}


\end{table}


A crucial step in falsification is that a rejected hypothesis implies that at least one premise in its explanation is false. But, it is undetermined exactly which one is false \parencite{Hines1988, Lakatos1970, Søberg2005, Weick1999}

The fact that such trade-offs are possible to ‘save a theory from falsification' has been used to argue against falsification \parencite{Søberg2005}(or research programs) with many such trade-offs are degenerate \parencite{Lakatos1970, Cross1982}(a research program in macroeconomics) while explicitly reflecting on the Lakatosian ideas at the basis of that judgment.

Step 0 and step 1 contribute by identifying a lack of accuracy. Step 0 may seem difficult, but the same creativity that is displayed in thinking of alternative explanations should also allow us to reinterpret results from theories that oppose that result. Regarding step 1, developing a CE does not require fully fleshed-out theories. Instead, CEs consist of the most straightforward, and commonly held, associations of concepts \parencite[][i,.,e,.,,, ,accepted, ,propositionsin]{Davis1971, Spector2011}

Steps 2 to 6 contribute by identifying ways to restore accuracy by trading-off simplicity and/or generalizability. Thus, one of the accepted propositions is negated and replaced by a proposition that is more complex and more ‘interesting' \parencite{Davis1971}(and the result was found for a solid planet). CE encourages including that challenge, even if another challenge ends up being more plausible.

Step 7 makes summarizes the complication; making explicit the degeneration that is forced upon the theory by the result. It is possible that a result is inconsistent with a CE because of bad measures, auxiliary premises, or research designs. The CE author can decide whether a CE with a step 7 that reads ‘Measure X does not capture concept A (in some context)' contributes enough to be worth the effort. If a challenged premise is paper-specific, the contribution may be small. On the other hand, the contribution may be large enough if measure X is typical. For example, see \textcite{Cook1979} discussing why insignificant results regarding the cognitive bias ‘sleeper effect' are due to operationalizations not appreciating theoretical nuances. Cook et al.'s (1979) paper is like a CE paper, except that CE reframes the discussion from ‘in this paper we remind people of some important nuances in the theory, which empirical studies have failed to appreciate, which led to insignificant results' to ‘insignificant results have forced us to appreciate the importance of some nuances, and in this paper, we make explicit the nuances we now believe to be important'. 



\subsection{Full circle}

Given those details, we can see how CE counteracts underreporting by improving meta-analyses. Meta-analyses use concept labels as inclusion criteria. For example, \textcite{Heugens2009}'s meta-analysis on ‘mimetic pressure's effect on isomorphism' uses a variety of concept labels to search for literature (e.g., ‘isomorphism', ‘institutional theory'). Underreporting practices cause studies to be described in terms of concepts that are supported by the result. Therefore, meta-analyses disproportionately include studies that support the theory \parencite{Murphy2019}. (Note also that while Tharking \parencite{Hollenbeck2017} and abduction \parencite{Locke2008, Schwab2017} do not mislead like HARKing, they still lead studies to be described in terms of concepts that are supported by the results). 

Enter CE. For example, a study finds a positive effect of ‘competition' (measured as the number of firms in the same industry) on ‘differentiation'. A CE for that result is that a greater number of firms in the same industry can be interpreted as mimetic pressure \parencite[][e,.,g,.]{Haveman1993}(systematically) fail to include results like these opposite to the theory. By contrast, after the CE is published, the result is described using theories that are not supported by it, so meta-analyses would include it. HARKing and not writing up tests could continue at the usual rate, but with CE, the proportion of rejected hypotheses among reported evidence would be greater (and closer to the true proportion).



\subsection{Conclusion}

Proposals to combat underreporting focus on preventing underreporting practices; e.g., de-emphasize p-values \parencite{Bettis2012, Bettis2012, Wasserstein2019, Schwab2011}

Moreover, CE is a useful practice, even if underreporting did not exist. First, CE also increases research reliability more directly. When CE is done by others than those who found the result, research reliability is increased simply by having an extra person thinking through the meaning of the data from a fresh perspective. Second, we put strain on others when collecting data. This comes with a responsibility to make the most of our data. CE helps fulfill that responsibility by reusing published results, in contrast to demands for efficient rather than comprehensive presentation, and novel findings.

In sum, I hope people use CE to learn more from the same findings and especially learn about, and from, those things that we currently miss due to underreporting. 



\subsubsection{Acknowledgements}

I would to thank the reviewers, Pablo Martin de Holan, Jana Retkowsky, Arjen van Witteloostuijn, and the OT reading group at Tilburg University for their encouragement and valuable feedback on an earlier version of this work.



\subsection{References}




\end{document}
